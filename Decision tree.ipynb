{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-código:\n",
    "\n",
    "    1. Encontre o melhor atributo e coloque-o no nó raiz da árvore.\n",
    "    2. Agora, divida o conjunto de treinamento do conjunto de dados em subconjuntos. \n",
    "       Ao fazer o subconjunto, certifique-se de que cada subconjunto do conjunto de dados de treinamento tenha o\n",
    "       mesmo valor para um atributo.\n",
    "    3. Encontre nós de folha em todos os ramos repetindo 1 e 2 em cada subconjunto.\n",
    "    \n",
    "    Ao implementar a árvore de decisão, passaremos pelas duas fases seguintes:\n",
    "\n",
    "    Fase de Construção\n",
    "        - Pré-processar o conjunto de dados.\n",
    "        - Dividir o conjunto de dados de treinar e testar usando o pacote sklearn do Python.\n",
    "        - Treine o classificador.\n",
    "    Fase Operacional\n",
    "        - Fazer previsões.\n",
    "        - Calcule a precisão.\n",
    "        \n",
    "\n",
    "# Termos usados no código:\n",
    "    O índice de Gini e o ganho de informações desses dois métodos são usados para selecionar os n atributos do \n",
    "    conjunto de dados cujo atributo seria colocado no nó raiz ou no nó interno. \n",
    "    Índice de Gini:\n",
    "        - O Índice de Gini é uma métrica para medir com que frequência um elemento escolhido aleatoriamente seria \n",
    "          identificado incorretamente.\n",
    "        - Isso significa que um atributo com menor índice de gini deve ser preferido.\n",
    "        - O Sklearn suporta o critério “gini” para o índice Gini e, por padrão, recebe o valor “gini”.\n",
    "    Entropia:\n",
    "        - Entropia é a medida da incerteza de uma variável aleatória, ela caracteriza a impureza de uma coleção \n",
    "        arbitrária de exemplos. Quanto maior a entropia, mais o conteúdo da informação.\n",
    "    Pontuação de precisão\n",
    "        - A pontuação de precisão é usada para calcular a precisão do classificador treinado.\n",
    "    Matriz de Confusão\n",
    "        - A Matriz de Confusão é usada para entender o comportamento do classificador treinado sobre o conjunto de \n",
    "        dados de teste ou validar o conjunto de dados.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando o conjunto de dados\n",
    "def importdata(): \n",
    "    balance_data = pd.read_csv('OnlineNewsPopularity.csv',sep= ',', header = 'infer')  \n",
    "    return balance_data \n",
    "\n",
    "\n",
    "# dividindo o conjunto de dados\n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Separando a variável de destino \n",
    "    X = balance_data.values[1:-1, 1:-1] \n",
    "    Ya = balance_data.values[1:-1, -1] \n",
    "      \n",
    "    Y = []\n",
    "    index = 0\n",
    "    for y in Ya:\n",
    "        if(int(y) >= 3395):\n",
    "            Y.insert(index, True)        \n",
    "        else:\n",
    "            Y.insert(index, False)\n",
    "        index += 1\n",
    "        \n",
    "    # Dividindo o conjunto de dados em treinamento e teste \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Indice de GINI ###########################################\n",
    "    \n",
    "# realizando treinamento com o índice gini\n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "    \n",
    "    # Criando o objeto classificador\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=60) \n",
    "  \n",
    "    # Realizando treinamento \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Entropia #####################################################\n",
    "    \n",
    "# realizar treinamento com entropia \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Árvore de decisão com entropia \n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 60) \n",
    "    \n",
    "    # Realizando treinamento\n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    \n",
    "    return clf_entropy \n",
    "  \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados usando indice de gini:\n",
      "Confusion Matrix:  [[9474    0]\n",
      " [2419    0]]\n",
      "Accuracy :  79.66030438072816\n",
      "Resultado usando entropia:\n",
      "Confusion Matrix:  [[9474    0]\n",
      " [2419    0]]\n",
      "Accuracy :  79.66030438072816\n"
     ]
    }
   ],
   "source": [
    "# fazendo previsões\n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Previsão no teste com gini Index \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    \n",
    "#     print(y_pred) \n",
    "    \n",
    "    return y_pred \n",
    "      \n",
    "#calculando a precisão\n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) \n",
    "    print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) \n",
    "    print(\"Report : \", classification_report(y_test, y_pred)) \n",
    "    \n",
    "     \n",
    "def main(): \n",
    "       \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    \n",
    "    print(\"Resultados usando indice de gini:\") \n",
    "      \n",
    "    # Previsão usando gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "    print(\"Resultado usando entropia:\")\n",
    "    \n",
    "    #Previsão usando Entropia \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy) \n",
    "      \n",
    "        \n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
