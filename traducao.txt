Um sistema proativo de suporte a decisões inteligente 
para prever a popularidade das notícias online

Abstrato. 
Devido à expansão da Web, a previsão de notícias online
A popularidade está se tornando um tópico de pesquisa moderno. Neste trabalho, propomos
um novo e inteligente Sistema de Apoio à Decisão Inteligente (IDSS) que
analisa artigos antes de sua publicação. Usando um amplo conjunto de
recursos (por exemplo, palavras-chave, conteúdo de mídia digital, popularidade anterior de notícias
mencionado no artigo), o IDSS primeiro prevê se um artigo se tornará
popular. Em seguida, otimiza um subconjunto dos recursos dos artigos que podem
mais facilmente ser alterada pelos autores, procurando por um aprimoramento
probabilidade de popularidade prevista. Usando um grande e recentemente coletado
conjunto de dados, com 39.000 artigos do site Mashable, realizamos uma
avaliação robusta de janelas rolantes de cinco modelos de última geração. Ao melhor
resultado foi fornecido por uma Floresta Random com um poder de discriminação
de 73%. Além disso, várias pesquisas locais de escalada estocástica foram
explorado. Ao otimizar 1000 artigos, o melhor método de otimização
obteve uma melhoria média de ganho de 15 pontos percentuais em termos de
a probabilidade de popularidade estimada. Estes resultados atestam a proposta
IDSS como uma ferramenta valiosa para autores de notícias online

1 Introducao

Sistemas de apoio à decisão (DSS) foram propostos em meados da década de 1960 e envolvem
uso da Tecnologia da Informação para apoiar a tomada de decisão. Devido aos avanços na
Neste campo (por exemplo, Data Mining, Metaheuristics), tem havido um interesse crescente
no desenvolvimento do Intelligent DSS (IDSS), que adota a Inteligência Artificial
técnicas de apoio à decisão [2]. O conceito de Business Intelligence Adaptável
(ABI) é um IDSS particular que foi proposto em 2006 [10]. Sistemas ABI combinam
previsão e otimização, que muitas vezes são tratados separadamente pelo IDSS, a fim de
para apoiar decisões de forma mais eficiente. O objetivo é primeiro usar modelos baseados em dados
para prever o que é mais provável que aconteça no futuro e, em seguida, use
métodos de otimização para procurar a melhor solução possível, dado o que pode ser
atualmente conhecido e previsto.
Dentro da expansão da Internet e da Web 2.0, também tem havido um crescimento
interesse em notícias on-line, que permitem uma disseminação fácil e rápida de informações em todo o mundo. Assim, prever a popularidade das notícias online está se tornando um
tendência de pesquisa recente (por exemplo, [1,3,8,13,15]). A popularidade é frequentemente medida considerando
o número de interações na Web e nas redes sociais (por exemplo, número de
compartilhamentos, gostos e comentários). Prever essa popularidade é valioso para os autores,
provedores de conteúdo, anunciantes e até ativistas / políticos (por exemplo, para
ou influenciar a opinião pública) [3]. Segundo Tatar et al. [16], existem dois
principais abordagens de previsão de popularidade: aquelas que usam recursos conhecidos apenas depois
publicação e aqueles que não usam tais recursos. A primeira abordagem é mais
comum (por exemplo, [1,8,9,13,15]). Como a tarefa de predição é mais fácil, maior previsão
precisões são frequentemente alcançadas. A última abordagem é mais escassa e, enquanto
menor desempenho de previsão pode ser esperado, as previsões são mais úteis,
permitindo (como realizado neste trabalho) para melhorar o conteúdo antes da publicação.
Usando a segunda abordagem, Petrovic et al. [12] previu o número de
retweets usando recursos relacionados ao conteúdo do tweet (por exemplo, número de hashtags,
menções, URLs, tamanho, palavras) e características sociais relacionadas ao autor
(por exemplo, número de seguidores, amigos, é o usuário verificado). Um total de 21 milhões
tweets foram recuperados durante outubro de 2010. Usando uma tarefa binária para discriminar
retuitado de posts não retweetados, uma pontuação máxima de 47% foi obtida quando
conteúdo tweet e recursos sociais foram usados. Da mesma forma, Bandari et al. [3]
focada em quatro tipos de recursos (fonte de notícias, categoria do artigo, subjetividade
idioma utilizado e nomes mencionados no artigo) para prever o número
de tweets que mencionam um artigo. O conjunto de dados foi recuperado do Feedzilla e
relacionado com uma semana de dados. Quatro métodos de classificação foram testados para prever
três classes de popularidade (1 a 20 tweets, 20 a 100 tweets, mais de 100; artigos
sem tweets foram descartados) e os resultados variaram de 77% a 84% de precisão,
para Naïve Bayes e Bagging, respectivamente. Finalmente, Hensinger et al. [7] testaram dois
tarefas de classificação binária de previsão: popular / impopular e atraente / não atraente,
quando comparado com outros artigos publicados no mesmo dia. Os dados
estava relacionado com dez agências de notícias inglesas relacionadas com um ano. Usando texto
recursos (por exemplo, mala de palavras do título e descrição, palavras-chave) e outros
características (por exemplo, data de publicação), combinadas com uma máquina de vetores de suporte
(SVM), os autores obtiveram melhores resultados para a tarefa
em comparação com a tarefa popular / impopular, alcançando resultados que variam de 62% a
86% de precisão para o primeiro e 51% a 62% para o segundo.
Neste artigo, propomos um novo IDSS proativo que analisa notícias on-line
antes de sua publicação. Assumindo uma abordagem ABI, a popularidade de um candidato
artigo é estimado pela primeira vez usando um módulo de previsão e, em seguida, uma otimização
módulo sugere mudanças no conteúdo e estrutura do artigo, a fim de
maximizar a sua popularidade esperada. Em nosso conhecimento, não há precedentes
trabalhos que abordaram essa abordagem ABI pró-ativa, combinando a previsão
e otimização para melhorar o conteúdo das notícias. O módulo de previsão usa um
grande lista de entradas que inclui recursos puramente novos (quando comparados com
literatura [3,7,12]): conteúdo de mídia digital (por exemplo, imagens, vídeo); popularidade anterior
de notícias referenciadas no artigo; número médio de compartilhamentos de palavras-chave anteriores
para publicação; e recursos de linguagem natural (por exemplo, polaridade de título, tópicos de Alocação de Dirichlet Latente). Adotamos a tarefa binária comum (popular / impopular)
e testar cinco métodos de última geração (por exemplo, Random Forest, Adaptive Boosting,
SVM), sob uma janela rolante realista. Além disso, usamos o moderno Mashable
(mashable.com/) conteúdo de notícias, que não foi estudado anteriormente ao prever
popularidade, e recolher um conjunto de dados recente e grande relacionado com os dois últimos
anos (um período de tempo muito maior quando comparado com a literatura). Além disso,
nós também otimizamos o conteúdo de notícias usando um método de busca local (stochastic hill
escalada) que procura melhorias em um conjunto parcial de recursos que podem ser
mais facilmente alterado pelo usuário.

2 Materiais e métodos
2.1 Aquisição de Dados e Preparação

Recuperamos o conteúdo de todos os artigos publicados nos últimos dois anos a partir de
Mashable, que é um dos maiores sites de notícias. Toda coleta de dados e
procedimentos de processamento descritos neste trabalho (incluindo a previsão e otimização
módulos) foram implementados em Python pelos autores. Os dados foram
coletados durante um período de dois anos, de 7 de janeiro de 2013 a 7 de janeiro de 2015.
Descartamos uma pequena porção de artigos para ocasiões especiais que não seguiam o
estrutura HTML geral, já que o processamento de cada tipo de ocasião exigiria
analisador específico. Também descartamos artigos muito recentes (menos de 3 semanas), já que
o número de ações da Mashable não alcançou convergência para alguns desses artigos
(por exemplo, com menos de 4 dias) e também queríamos manter um número constante de
artigos por teste definidos em nossa estratégia de avaliação de janelas rolantes (ver Seção 2.3).
Após esse pré-processamento, terminamos com um total de 39.000 artigos, conforme
Tabela 1. Os dados coletados foram doados para o repositório UCI Machine Learning
(http://archive.ics.uci.edu/ml/).

                        Tabela 1

Nós extraímos um conjunto extenso (total de 47) recursos do código HTML
a fim de tornar esses dados adequados para modelos de aprendizagem, como mostra a Tabela 2.
Na tabela, os tipos de atributos foram classificados em: number - integer value;
proporção - dentro de [0, 1]; bool - {0, 1}; e nominal. Tipo de Coluna mostra dentro
parênteses (#) o número de variáveis ​​relacionadas com o atributo. similarmente a
o que é executado em [13,15], realizamos uma transformação logarítmica para escala
os recursos numéricos ilimitados (por exemplo, número de palavras no artigo), enquanto o
os atributos nominais foram transformados com a codificação comum 1-de-C.
Selecionamos uma grande lista de características que descrevem diferentes aspectos da
artigo e que foram considerados possivelmente relevantes para influenciar o número de ações. Algumas das características dependem de particularidades do Mashable
serviço: os artigos freqüentemente fazem referência a outros artigos publicados no mesmo serviço; e
os artigos têm metadados, como palavras-chave, tipo de canal de dados e número total
de ações (ao considerar o Facebook, Twitter, Google+, LinkedIn, StumbleUpon
e Pinterest). Assim, extraímos os valores mínimo, médio e máximo
número de ações (conhecidas antes da publicação) de todos os links da Mashable citados no
artigo. Da mesma forma, classificamos todos os compartilhamentos de média de palavras-chave de artigos (conhecidos antes da publicação),
para obter as piores, médias e melhores palavras-chave. Para cada um desses
palavras-chave, extraímos o número mínimo, médio e máximo de compartilhamentos.
As categorias do canal de dados são: “lifestyle”, “bus”, “entertainment”, “socmed”,
“Tech”, “viral” e “world”.
Também extraímos vários recursos de processamento de linguagem natural. O latente
O algoritmo Dirichlet Allocation (LDA) [4] foi aplicado a todos os textos do Mashable
(conhecido antes da publicação) para primeiro identificar os cinco principais tópicos relevantes
e, em seguida, medir a proximidade do artigo atual para esses tópicos. Para calcular o
análise de subjetividade e sentimento de polaridade, adotamos o padrão de mineração web
módulo (http://www.clips.ua.ac.be/pattern) [5], permitindo o cálculo
dos escores de polaridade e subjetividade do sentimento.

                        Tabela 2

2.2 Sistema Inteligente de Suporte à Decisão

Seguindo o conceito ABI, o IDSS proposto contém três módulos principais
(Figura 1): extração e processamento de dados, previsão e otimização. o
primeiro módulo executa os passos descritos na Seção 2.1 e é responsável
para coletar os artigos online e computar seus respectivos recursos. O módulo de previsão primeiro recebe os dados processados ​​e os divide em treinamento,
conjuntos de validação e teste (separação de dados). Então, ajusta e ajusta a classificação
modelos (modelo de treinamento e seleção). Em seguida, o melhor modelo de classificação
é armazenado e usado para fornecer previsões de sucesso do artigo (estimativa de popularidade).
Finalmente, o módulo de otimização procura por melhores combinações de um subconjunto de
as características atuais do conteúdo do artigo. Durante esta busca, há um pesado
uso do modelo de classificação (o oráculo). Além disso, alguns dos novos recursos pesquisados
combinações podem exigir uma recomputação dos respectivos recursos (por exemplo,
palavra-chave média número mínimo de compartilhamentos). Na figura, essa dependência é
representado pela seta entre a extração de recursos e a otimização. Uma vez
a otimização estiver concluída, uma lista de sugestões de alteração de artigos é fornecida para
o usuário, permitindo que ele tome uma decisão.


                    Figura 1

2.3 Módulo de Previsão

Adotamos a biblioteca Scikit learn [11] para ajustar os modelos de previsão. similarmente
para o que é executado em [12,3,7], assumimos uma tarefa de classificação binária, onde
um artigo é considerado “popular” se o número de ações for superior a um valor fixo
limiar de decisão (D1), senão é considerado “impopular”.
Neste trabalho, testamos cinco modelos de classificação: Floresta Aleatória (RF);
Reforço Adaptativo (AdaBoost); SVM com um kernel de Função de Base Radial (RBF);
K-vizinhos mais próximos (KNN) e Naïve Bayes (NB). Uma pesquisa de grade foi usada
buscar os melhores hiperparâmetros de: RF e AdaBoost (número de árvores);
SVM (parâmetro de trade-off C); e KNN (número de vizinhos). Durante esta grade
pesquisa, os dados de treinamento foram divididos internamente em treinamento (70%) e validação
sets (30%) usando uma divisão aleatória de holdout. Uma vez que o melhor hiperparâmetro é
selecionado, o modelo é adequado para todos os dados de treinamento.
A curva característica de operação do receptor (ROC) mostra o desempenho de
um classificador de duas classes na faixa de possíveis valores de limiar (D2 ∈ [0, 1]),
traçando um menos a especificidade (eixo x) versus a sensibilidade (eixo y) [6]. Em
Neste trabalho, os métodos de classificação assumem uma modelagem probabilística, onde
classe é considerada positiva se sua probabilidade prevista for p> D2. Nós computamos
várias métricas de classificação: Precisão, Precisão, Recall, pontuação F1 (todos usando
um D2 fixo = 0,5); ea Área Sob o ROC (AUC, que considera todos os
Valores D2). A métrica AUC é a métrica mais relevante, pois mede a
o poder discriminatório do classificador e é independente do valor D2 selecionado [6].
O método ideal deve apresentar uma AUC de 1,0, enquanto uma AUC de 0,5 indica
classificador aleatório. Para conseguir uma avaliação robusta, adotamos uma janela rolante
análise [14]. Sob esta avaliação, uma janela de treinamento de amostras consecutivas W
é usado para ajustar o modelo e, em seguida, as previsões L são executadas. Em seguida, o treinamento
janela é atualizada, substituindo as amostras mais antigas L com L mais recentes,
para ajustar um novo modelo e executar um novo conjunto de previsões L e assim por diante.

2.4 Otimização

A pesquisa local otimiza uma meta pesquisando na vizinhança de uma inicial
solução. Esse tipo de pesquisa é adequado ao nosso módulo de otimização de IDSS, uma vez que recebe
um artigo (a solução inicial) e, em seguida, tenta aumentar sua popularidade prevista
probabilidade procurando por possíveis alterações de artigos (dentro da vizinhança
a solução inicial). Um exemplo de um método de busca local simples é o hill climbing,
que busca iterativamente dentro da vizinhança da solução atual
e atualiza tal solução quando uma melhor é encontrada, até um ótimo local
é atingido ou o método é interrompido. Neste artigo, usamos uma colina estocástica
escalada [10], que funciona como a subida em montanha, exceto as piores soluções
pode ser selecionado com uma probabilidade de P. Testamos vários valores de P, variando
de P = 0 (subida de colina) a P = 1 (busca aleatória de Monte-Carlo).
Para avaliar a qualidade das soluções, a pesquisa local maximiza a
probabilidade para a classe “popular”, conforme previsto pelo melhor modelo de classificação.
Além disso, a pesquisa é realizada apenas sobre um subconjunto de recursos que são mais
adequado para ser alterado pelo autor (adaptação do conteúdo ou alteração no dia de
publicação), conforme detalhado na Tabela 3. Em cada iteração, a
espaço assume pequenas perturbações (aumento ou diminuição) no recurso original
valores. Por exemplo, se o número atual de palavras no título for n = 5, então um
busca é executada por um tempo menor
0 = 4) ou mais (n
0 = 6) título. Desde o dia de
a semana foi representada como uma variável nominal, uma seleção aleatória para um diferente
dia é assumido na perturbação. Da mesma forma, dado que o conjunto de palavras-chave (K)
não é numérico, uma estratégia de perturbação diferente é proposta. Para um particular
artigo, calculamos uma lista de palavras-chave sugeridas K0
que inclui palavras que
aparecem mais de uma vez no texto e que foram usados ​​como palavras-chave em
artigos. Para manter o problema computacionalmente tratável, consideramos apenas
melhores cinco palavras-chave em termos de suas ações médias anteriores. Então, nós geramos
perturbações adicionando uma das palavras-chave sugeridas ou removendo uma das
as palavras-chave originais. O desempenho médio ao otimizar N artigos (ou seja, N pesquisas locais) é avaliado usando o Ganho Médio (MG) e a Taxa de Conversão
(CR):

                Equação (1)

onde Qi denota a qualidade (probabilidade de popularidade estimada) para o original
artigo (i), Q'_i é a qualidade obtida usando a pesquisa local, U é o número de
artigos impopulares (probabilida- de estimada ≤ D_2, para todos os N artigos originais) e
U' é o número de artigos convertidos (a probabilidade estimada original era ≤ D_2
mas depois da otimização mudou para> D_2 .

                Tabela 3

3 experimentos e resultados

3.1 Previsão

Para os experimentos de previsão, adotamos o esquema de janelas rolantes com
um tamanho de janela de treinamento de W = 10, 000 e realizando L = 1, 000 previsões
em cada iteração. Sob esta configuração, cada modelo de classificação é treinado
29 vezes (iterações), produzindo 29 conjuntos de previsão (cada um de tamanho L). Para definir
uma classe popular, usamos um valor fixo de D1 = 1, 400 partes, o que resultou
em uma distribuição de classe balanceada “popular” / “impopular” no primeiro conjunto de treinamento
(primeiros 10 000 artigos). A pesquisa de grade selecionada varia para os hiperparâmetros
foram: RF e AdaBoost - número de árvores 10 {10, 20, 50, 100, 200, 400}; SVM -
C ∈ {2^0, 2^1, ... 2^6}; e KNN - número de vizinhos 1 {1, 3, 5, 10, 20}.
