{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Desenvolvimento de uma rede neural que maximiza os acertos se uma notícia irá ser popular </h3>\n",
    "<h5> Alunas: Elaine Sangali, Ana Frozza </h5> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Introdução </h3>\n",
    "<p> O presente trabalho tem como objetivo projetar uma rede neural artificial que maximize os acertos de uma base de dados de notícias, onde o objetivo é prever se uma notícia obterá sucesso ou não. Para o desenvolvimento da rede será utilizado o Keras. Será testado vários métodos e valores de entradas para tentar obter o maior número de acerto possível. O conteúdo teórico deste trabalho pode ser encontrado no site do </p> \n",
    "[deeplearningbook.com.br](http://deeplearningbook.com.br/capitulos/). \n",
    "\n",
    "<h4> Redes neurais</h4>\n",
    "\n",
    "<p> Uma rede neural tem como objetivo imitar como o cérebro humano aprende. Ela é um mecanismo de aprendizado de máquina muito poderoso, à medida que uma tarefa se torna complicada, há vários perceptrons que formam uma rede que transmitem informações entre si. Um perceptron representa um neurônio. O modelo do Perceptron foi desenvolvido nas décadas de 1950 e 1960 pelo cientista Frank Rosenblatt. Hoje é mais utilizado outros modelos de neurônnios artificias, mas esse seria um modelo básico, como mostra a figura 1, onde o perceptron rece várias entradas, x1; x2; x3 e produz uma única saída binária. </p>\n",
    "\n",
    "![modelo basico perceptron](https://i0.wp.com/deeplearningbook.com.br/wp-content/uploads/2017/12/perceptron.png?w=280) <center> *figura 1 - Modelo básico de um perceptron* </center>\n",
    "\n",
    "<p> No modelo da figura 1, o perceptron possui três entradas, x1; x2; x3, para calcular a saída, Rosenblatt introduziu pesos, w1; w2; w3, números reais que representam a importância das entradas para a saída, assim a entrada x1 possui peso w1, x2 peso w2 e x3 peso w3. A saída do neurônio é binária, 0 ou 1, e é determinada pela soma ponderada, Σjwjxj, menor ou maior do que algum valor limiar (threshold), como mostra a figura 2. </p>\n",
    "\n",
    "![termo algébrico](https://i2.wp.com/deeplearningbook.com.br/wp-content/uploads/2017/12/output.png?w=362) <center> *figura 2 - Modelo algébrico da saída de um perceptron* </center>\n",
    "\n",
    "<p> O modelo da figura 1 seria um modelo básico de um perceptron, mas atualmente é utilizado modelos mais completos que obtem melhores resultados, como o modelo da figura 3. O modelo da figura 1, simplesmente utiliza uma somatória do produto dos pesos com as entradas, mas esse é um modelo muito simples para determinados problemas. No modelo da figura 3, a função de ativação g(.) usará a saída u em uma função, e o resultado do perceptron será a saída da função g. O simbolo Θ representa o viés (bias), que são utilizados no lugar do threshold, os bias são ajustadas da mesma forma que os pesos sinápticos, o bias permite que um neurônio apresente a saída não nula ainda que todas as suas entradas sejam nulas. O bias representa o quão fácil é fazer o perceptron produzir um 1 (disparar). Um perceptron com um viés muito grande tem uma tendência a emitir um 1, e muito pequeno de emitir 0. </p>\n",
    "\n",
    "![modelo matemático neuronio](https://i0.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/01/neuronio.jpeg?resize=300%2C137)  <center> *figura 3 - Modelo de perceptron com bia e função de ativação* </center>\n",
    "\n",
    "<p>O novo modelo utiliza uma função de soma um pouco diferente, ainda é realizado a soma dos produtos dos pesos com as entradas, mas no fim é somado o valor do viés, como mostra a figura 4.</p>\n",
    "\n",
    "![modelo matemático neuronio](https://i1.wp.com/deeplearningbook.com.br/wp-content/uploads/2017/12/formula.png?w=295)  <center> *figura 4 - Modelo algébrico com o viés* </center>\n",
    "\n",
    "<p>Um único perceptron não consegue resolver os problemas grandes, para isso é necessário uma rede de perceptrons. Há três categorias de tipos de redes de perceptrons (Arquiteturas):<p>\n",
    "<ol>\n",
    "    <li>Redes Neurais Feed-Forward: São mais comuns, a primeira camada é a entrada e a última camada é a saída, se houver uma camada oculta entre as duas, é chamado de redes neurais profundas(Deep Learning). A rede calcula uma série de transformação que altera a semelhança entre os casos, as atividades dos neurônios em cada camada são uma função não-linear das atividades na camada anterior. </li>\n",
    "    <li>Redes Recorrentes: Essa rede é utilizada quando para se obter o valor de saída atual é necessário analisar o valor do passado. Essa rede é equivalente a redes muito profundas com uma camada oculta por fatia de tempo; exceto que eles usam os mesmos pesos em cada fatia de tempo e recebem entrada em cada fatia. Eles têm a capacidade de lembrar informações em seu estado oculto por um longo período de tempo, mas é muito difícil treiná-las para usar esse potencial. Podem possuir uma dinâmica complicada, sendo difíceis de treinar, mas são mais biologicamente realistas.</li>\n",
    "    <li>Redes Conectadas Simetricamente: São como as redes recorrentes mas elas possuem o mesmo peso em ambas as direções.  As redes conectadas simetricamente sem unidades ocultas são chamadas de “Redes Hopfield”. As redes conectadas simetricamente com unidades ocultas são chamadas de “Máquinas de Boltzmann”. </li>\n",
    "</ol>    \n",
    "\n",
    "O trabalho atual se enquadra na categoria Redes Neurais Feed-Forward, a arquitetura utilizada é a Redes Multilayer Perceptrons (MLP), a rede MLP é composta por mais de um perceptron, e possui uma camada de entrada, uma de saída que toma uma decisão sobre a entrada, e entre as duas pode haver várias camadas ocultas. O MLP é muito utilizado em problemas de aprendizagem supervisionados, ele treina um conjunto de pares entrada-saída e aprende a modelar a correlação entre as entradas e saídas, no treinamento é realizado o ajuste dos parâmetros, pesos e bias da rede para conseguir minimizar o erro.  O backpropagation é usado para fazer os ajustes dos pesos e de bias em relação ao erro, e o próprio erro pode ser medido de várias maneiras, inclusive pelo erro quadrático médio.\n",
    "\n",
    "<h4> Base de dados: Online News Popularity </h4>\n",
    "\n",
    "A base de dados [Online News Popularity](http://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) possui 60 atributos de várias notícias a ser analisados pela rede neural mais 1 atributo que possui o valor alvo, os atributos possuem o seguinte significado:\n",
    "\n",
    "<ol>\n",
    "<li>url: Url da notícia</li>\n",
    "<li>timedelta: Dias entre a publicação da notícia e a aquisição do conjunto de dados (não-preditiva)</li>\n",
    "<li>n_tokens_title: Quantidade de palavras do título</li>\n",
    "<li>n_tokens_content: Quantidade de palavras do conteúdo</li>\n",
    "<li>n_unique_tokens: Quantidade de palavras únicas no conteúdo</li>\n",
    "<li>n_non_stop_words: Taxa de palavras sem parar no conteúdo</li>\n",
    "<li>n_non_stop_unique_tokens: Quantidade de palavras não únicas no conteúdo</li>\n",
    "<li>num_hrefs: Número de links</li>\n",
    "<li>num_self_hrefs: Número de links para outras notícias publicados pela Mashable </li>\n",
    "<li>num_imgs: Número de imagens</li>\n",
    "<li>num_videos: Número de vídeos </li>\n",
    "<li>average_token_length: Tamanho médio das palavras no conteúdo</li>\n",
    "<li>num_keywords: Número de palavras-chave nos metadados</li>\n",
    "<li>data_channel_is_lifestyle: É o canal de dados 'Lifestyle'?</li>\n",
    "<li>data_channel_is_entertainment: O canal de dados é 'Entretenimento'?</li>\n",
    "<li>data_channel_is_bus: É o canal de dados 'Business'?</li>\n",
    "<li>data_channel_is_socmed: É o canal de dados 'Social Media'?</li>\n",
    "<li>data_channel_is_tech: O canal de dados é 'Tech'? </li>\n",
    "<li>data_channel_is_world: é o canal de dados 'World'? </li>\n",
    "<li>kw_min_min: Pior palavra-chave (min. Compartilhamentos)</li>\n",
    "<li>kw_max_min: Pior palavra-chave (máx. Compartilhamentos)</li>\n",
    "<li>kw_avg_min: Pior palavra-chave (média de compartilhamentos)</li>\n",
    "<li>kw_min_max: Melhor palavra-chave (min. Compartilhamentos)</li>\n",
    "<li>kw_max_max: Melhor palavra-chave (máx. Compartilhamentos)</li>\n",
    "<li>kw_avg_max: Melhor palavra-chave (média de compartilhamentos)</li>\n",
    "<li>kw_min_avg: média palavra-chave (min. partes)</li>\n",
    "<li>kw_max_avg: média palavra-chave (máx. compartilhamentos)</li>\n",
    "<li>kw_avg_avg: média palavra-chave (média de compartilhamentos)</li>\n",
    "<li>self_reference_min_shares: minimo de ações de notícias referenciados em Mashable</li>\n",
    "<li>self_reference_max_shares: máx. ações de notícias referenciados em Mashable</li>\n",
    "<li>self_reference_avg_sharess: média. ações de notícias referenciados em Mashable</li>\n",
    "<li>weekday_is_monday: A notícia foi publicado na segunda-feira?</li>\n",
    "<li>weekday_is_tuesday: A notícia foi publicado em uma terça-feira?</li>\n",
    "<li>weekday_is_wednesday: A notícia foi publicado em uma quarta-feira?</li>\n",
    "<li>weekday_is_thursday: A notícia foi publicado em uma quinta-feira?</li>\n",
    "<li>weekday_is_friday: A notícia foi publicado em uma sexta-feira?</li>\n",
    "<li>weekday_is_saturday: A notícia foi publicado em um sábado?</li>\n",
    "<li>weekday_is_sunday: A notícia foi publicado em um domingo?</li>\n",
    "<li>is_weekend: A notícia foi publicado no final de semana?</li>\n",
    "<li>LDA_00: Proximidade do tópico 0 do LDA</li>\n",
    "<li>LDA_01: Proximidade do tema 1 do LDA</li>\n",
    "<li>LDA_02: Proximidade do tópico 2 do LDA</li>\n",
    "<li>LDA_03: Proximidade do tema 3 do LDA</li>\n",
    "<li>LDA_04: Proximidade do tema 4 do LDA</li>\n",
    "    \n",
    "<li>global_subjectivity: Subjetividade do texto</li>\n",
    "<li>global_sentiment_polarity: polaridade do sentimento de texto</li>\n",
    "<li>global_rate_positive_words: Taxa de palavras positivas no conteúdo</li>\n",
    "<li>global_rate_negative_words: Taxa de palavras negativas no conteúdo</li>\n",
    "<li>rate_positive_words: Taxa de palavras positivas entre tokens não neutros</li>\n",
    "<li>rate_negative_words: Taxa de palavras negativas entre tokens não neutros</li>\n",
    "<li>avg_positive_polarity: média polaridade de palavras positivas</li>\n",
    "<li>min_positive_polarity: min. polaridade de palavras positivas</li>\n",
    "<li>max_positive_polarity: máx. polaridade de palavras positivas</li>\n",
    "<li>avg_negative_polarity: média polaridade de palavras negativas</li>\n",
    "    <li>min_negative_polarity: min. polaridade de palavras negativas</li>\n",
    "<li>max_negative_polarity: máx. polaridade de palavras negativas</li>\n",
    "<li>title_subjectivity: subjetividade do título</li>\n",
    "<li>title_sentiment_polarity: polaridade do título</li>\n",
    "<li>abs_title_subjectivity: Nível de subjetividade absoluta</li>\n",
    "<li>abs_title_sentiment_polarity: nível de polaridade absoluta</li>\n",
    "<li>ações: Número de ações (alvo)</li>\n",
    "</ol>\n",
    "\n",
    "Este conjunto de dados resume um conjunto heterogêneo de características sobre artigos publicados pela Mashable em um período de dois anos. O objetivo é prever o número de compartilhamentos nas redes sociais (popularidade). A base de dados contém 39644 exemplos. A média de compartilhamentos é de 3395, assim, valores abaixo dessa média serão considerados não populares, e valores iguais ou acima dessa média serão considerados populares.\n",
    "\n",
    "<h3> Desenvolvimento </h3>\n",
    "Inicialmente será importado as bibliotecas que serão utilizadas no projeto, e será utilizado um código simples do keras de classificação binária, pois o resultado é binário, ou é popular, ou não é.\n",
    "\n",
    "Para separar a base em treino e teste foi utilizado o train_test_split como mostra a linha 21, para teste foi separado 30% da base. Além do teste e do treino, também foi separado 25% do treino para validação, afim de não ter uma base viciada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas necessárias no projeto\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.svm import SVC\n",
    "from keras import utils as np_utils\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open('OnlineNewsPopularity.csv','r'), delimiter=',') #lendo os atributos da base de dados\n",
    "\n",
    "rows = np.array(list(reader))\n",
    "labels = rows[0] #vetor com os labels das caracteristicas\n",
    "\n",
    "X = rows[1:-1, 1:-1] #vetor de caracteristicas\n",
    "Ya = rows[1:-1, -1] #Vetor de resultados\n",
    "\n",
    "Y = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "for y in Ya:\n",
    "    if(int(y) >= 3395):\n",
    "        Y.insert(index, True)        \n",
    "    else:\n",
    "        Y.insert(index, False)\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y) #separando em um conjunto de treino e outro de teste\n",
    "\n",
    "num_input = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Overfitting </h4>\n",
    "O código inicial está representado a seguir demonstra o overfitting . O overfitting ocorre quando utilizamos neurônios igual ou maiores que 96 na segunda camada.\n",
    "\n",
    "Como é observado na figura 6, o overfitting acontece devido ao fato de a rede neural apresentar melhores resultados no treino do que no teste.\n",
    "![código overfit](https://uploaddeimagens.com.br/images/001/743/022/full/overfit.png?1543063949)  <center> *figura 6 - Resultado do overfitting* </center>\n",
    "\n",
    "A figura 7 mostra a rede neural utilizando 90 neurônios, nessa fase não acontece o overfitting, pois o teste obtem melhores resultados que o treino.\n",
    "![código overfit](https://uploaddeimagens.com.br/images/001/743/140/full/overfit2.png?1543073207)  <center> *figura 7 - Resultado do overfitting* </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 6938 samples\n",
      "Epoch 1/50\n",
      "20812/20812 [==============================] - 12s 600us/step - loss: 5.5665 - acc: 0.6525 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 2/50\n",
      "20812/20812 [==============================] - 12s 580us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 3/50\n",
      "20812/20812 [==============================] - 12s 575us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 4/50\n",
      "20812/20812 [==============================] - 12s 558us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 5/50\n",
      "20812/20812 [==============================] - 12s 592us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 6/50\n",
      "20812/20812 [==============================] - 12s 582us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 7/50\n",
      "20812/20812 [==============================] - 14s 651us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 8/50\n",
      "20812/20812 [==============================] - 11s 546us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 9/50\n",
      "20812/20812 [==============================] - 13s 613us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 10/50\n",
      "20812/20812 [==============================] - 13s 605us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 11/50\n",
      "20812/20812 [==============================] - 13s 613us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 12/50\n",
      "20812/20812 [==============================] - 14s 664us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 13/50\n",
      "20812/20812 [==============================] - 14s 686us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 14/50\n",
      "20812/20812 [==============================] - 12s 600us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 15/50\n",
      "20812/20812 [==============================] - 12s 584us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 16/50\n",
      "20812/20812 [==============================] - 11s 537us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 17/50\n",
      "20812/20812 [==============================] - 12s 588us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 18/50\n",
      "20812/20812 [==============================] - 13s 604us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 19/50\n",
      "20812/20812 [==============================] - 13s 606us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 20/50\n",
      "20812/20812 [==============================] - 12s 591us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 21/50\n",
      "20812/20812 [==============================] - 11s 521us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 22/50\n",
      "20812/20812 [==============================] - 11s 530us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 23/50\n",
      "20812/20812 [==============================] - 11s 530us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 24/50\n",
      "20812/20812 [==============================] - 11s 546us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 25/50\n",
      "20812/20812 [==============================] - 11s 531us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 26/50\n",
      "20812/20812 [==============================] - 11s 510us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 27/50\n",
      "20812/20812 [==============================] - 11s 528us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 28/50\n",
      "20812/20812 [==============================] - 11s 510us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 29/50\n",
      "20812/20812 [==============================] - 11s 552us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 30/50\n",
      "20812/20812 [==============================] - 11s 507us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 31/50\n",
      "20812/20812 [==============================] - 11s 507us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 32/50\n",
      "20812/20812 [==============================] - 11s 513us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 33/50\n",
      "20812/20812 [==============================] - 13s 621us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 34/50\n",
      "20812/20812 [==============================] - 15s 708us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 35/50\n",
      "20812/20812 [==============================] - 12s 569us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 36/50\n",
      "20812/20812 [==============================] - 13s 621us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 37/50\n",
      "20812/20812 [==============================] - 12s 563us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 38/50\n",
      "20812/20812 [==============================] - 11s 531us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 39/50\n",
      "20812/20812 [==============================] - 11s 539us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 40/50\n",
      "20812/20812 [==============================] - 10s 496us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 41/50\n",
      "20812/20812 [==============================] - 10s 492us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 42/50\n",
      "20812/20812 [==============================] - 12s 562us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 43/50\n",
      "20812/20812 [==============================] - 14s 659us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 44/50\n",
      "20812/20812 [==============================] - 13s 605us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 45/50\n",
      "20812/20812 [==============================] - 13s 627us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 46/50\n",
      "20812/20812 [==============================] - 13s 637us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 47/50\n",
      "20812/20812 [==============================] - 12s 553us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 48/50\n",
      "20812/20812 [==============================] - 13s 606us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 49/50\n",
      "20812/20812 [==============================] - 12s 582us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "Epoch 50/50\n",
      "20812/20812 [==============================] - 13s 621us/step - loss: 12.6922 - acc: 0.2039 - val_loss: 12.6978 - val_acc: 0.2035\n",
      "11893/11893 [==============================] - 4s 335us/step\n",
      "\n",
      " Taxa de acerto: 20.38%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d25b0182b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d25c629208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input))\n",
    "model.add(Dense(units=59, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(\"\\n Taxa de acerto: %.2f%%\" % (loss_and_metrics[1]*100))\n",
    "\n",
    "#optimizer : sgd \n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Regularização </h4>\n",
    "\n",
    "A regularização pode ajudar a reduzir o overfitting. Analisaremos os efeitos de três técnicas de regularização no \n",
    "código, a técnica L1, L2 e Dropout. A intenção da regularização é fazer com que a rede prefira aprender pesos pequenos. Os pesos grandes só são permitidos se melhorarem bastante a primeira parte da função de custo, ou seja, ela tenta encontrar pequenos pesos e minimizar a função de custo original.\n",
    "\n",
    "Tanto na técnica L1 quanto na L2 o resultado é a diminuição dos valores dos pesos, mas a maneira como os pesos diminuem é diferente. Quando um peso específico tem uma grande magnitude, a regularização L1 reduz o peso muito menos do que a Regularização L2, mas, quando |w| é pequeno, a regularização L1 reduz o peso muito mais do que a regularização L2, assim a regularização L1 tende a concentrar o peso da rede em um número relativamente pequeno de conexões de alta importância, enquanto os outros pesos são direcionados para zero.\n",
    "\n",
    "Configurações utilizadas no modelo de regularização L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input, activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(units=59, activation='relu', activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essas configurações no L1 foi obtido uma taxa de acerto de 79,63%. A figura 8 demostra o histórico da acurácia para o L1 com valor de 0.1.\n",
    "![l1 - 0,1](https://uploaddeimagens.com.br/images/001/744/765/full/l1-0_01.png?1543200998)  <center> *figura 8 - Histórico de acurácia para L1 = 0.1* </center>\n",
    "\n",
    "A figura 9 demostra o histórico da acurácia para o L1 com valor de  de 0.01 nesse caso o resultado do teste apresentou ser pior do que o utilizado com 0.1, pois a taxa de acerto obtida foi de 79,60%.\n",
    "\n",
    "![l1 - 0,01](https://uploaddeimagens.com.br/images/001/744/780/full/l1-0_01.png?1543201813)  <center> *figura 9 - Histórico de acurácia para L1 = 0.01* </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações utilizadas no modelo de regularização L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(units=59, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essas configurações no L2 foi obtido uma taxa de acerto de 79,62%. A figura 10 demostra o histórico da acurácia para o L1 com valor de 0.01, a média da taxa de acerto de treino é de 79,61% e de teste é de 79,65%.\n",
    "![l1 - 0,01](https://uploaddeimagens.com.br/images/001/744/708/full/l2-0_01.png?1543197697)  <center> *figura 10 - Histórico de acurácia para L2 = 0.01* </center>\n",
    "\n",
    "A figura 11 demostra o histórico da acurácia para o L2 com valor de  de 0.1, nesse caso o resultado do teste apresentou ser praticamente o mesmo que o anterior.\n",
    "\n",
    "![l1 - 0,1](https://uploaddeimagens.com.br/images/001/744/722/full/l2-0_1.png?1543199138)  <center> *figura 11 - Histórico de acurácia para L2 = 0.1* </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dropout é uma técnica diferente da L1 e L2, ele não depende da modificação da função de custo, ele modifica a própria rede. O Dropout elimina aleatoriamente (e temporariamente) alguns dos neurônios ocultos na rede, mas deixa os neurônios de entrada e saída intocados.\n",
    "\n",
    "Configurações utilizadas no Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=59, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o Dropout de 0.5 foi obtido uma taxa de acerto de 79,62%, a figura 12 mostra o histórico da acurácia na fase de treino e teste.\n",
    "\n",
    "![drop - 0,5](https://uploaddeimagens.com.br/images/001/744/803/full/drop-0_5.png?1543204505) <center> *figura 12 - Histórico de acurácia para Dropout = 0.5* </center>\n",
    "\n",
    "Com o Dropout de 0.3 foi obtido uma taxa de acerto de 79,62%, a figura 13 mostra o histórico da acurácia na fase de treino e teste.\n",
    "\n",
    "![drop - 0,3](https://uploaddeimagens.com.br/images/001/744/821/full/drop-0_3.png?1543206419) <center> *figura 13 - Histórico de acurácia para Dropout = 0.3* </center>\n",
    "\n",
    "Com o Dropout de 0.7 foi obtido uma taxa de acerto de 79,62%, a figura 14 mostra o histórico da acurácia na fase de treino e teste.\n",
    "\n",
    "![drop - 0,7](https://uploaddeimagens.com.br/images/001/744/819/full/drop-0_7.png?1543206380) <center> *figura 14 - Histórico de acurácia para Dropout = 0.7* </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Hiperparâmetros </h4>\n",
    "\n",
    "Inicialmente será decidido o número de neuronios utilizados na segunda e terceira camada, como mostra o código a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=80, activation='relu', input_dim=num_input))\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=5, batch_size=16, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figura 15 mostra o histórico da acurácia obtido, utilizando 20 neuronios na segunda camada oculta. A taxa de acerto foi de 20,37%.\n",
    "\n",
    "![hp - 20](https://uploaddeimagens.com.br/images/001/744/843/full/hp-01.pnh.PNG?1543210289) <center> *figura 15 - Histórico de acurácia para 2² camada oculta = 20* </center>\n",
    "\n",
    "A figura 16 mostra o histórico da acurácia obtido, utilizando 59 neuronios na segunda camada oculta. A taxa de acerto foi de 79,62%. Foi testado até valores maiores, como 200 neuronios, mas apresentou o mesmo resultado, portanto a segunda camada oculta irá utilizar 59 neuronios.\n",
    "\n",
    "![hp - 59](https://uploaddeimagens.com.br/images/001/744/842/full/hp-02.PNG?1543210194) <center> *figura 16 - Histórico de acurácia para 2² camada oculta = 59* </center>\n",
    "\n",
    "Como se pode observar, no primeiro caso ocorre o overfitting, então concluimos que valores baixos na segunda camada oculta não é bom, por isso será utilizado 59 neuronios.\n",
    "\n",
    "Outro hiperparâmetro que pode ser ajustado é quantidade de dados retirados do treino para validação, foi testado utilizar valores de 25%, 30% e 40%, mas não houve variação na taxa de acerto, a mesma se manteve em 79.62% Então será mantido com o valor de 25%. Além da validação foi feito modificações no tamanho do batch, mas a medida que foi aumentando o valor do batch, o mesmo manteve a taxa de acerto, até cair para 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'ADAM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-c7c65f5e2fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'ADAM'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=80, activation='relu', input_dim=num_input))\n",
    "model.add(Dense(units=59, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=5, batch_size=16, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(\"\\n Taxa de acerto: %.2f%%\" % (loss_and_metrics[1]*100))\n",
    "#optimizer : sgd \n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
